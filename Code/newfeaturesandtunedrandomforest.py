# -*- coding: utf-8 -*-
"""NewFeaturesAndTunedRandomForest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Idlz-fTvGinEKH-5iQ2xZfaDjqovvbAB

Import Libraries
"""

# basic imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime

# specific imports
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import RandomizedSearchCV

"""Import Dataset"""

# Assign data to variable
dataset = pd.read_csv('HousingData.csv')
dataset = dataset.head(229)

# Take a small look at the dataframe produced
print(dataset.head())
print(dataset.shape)

"""Preprocess Data (normalize it!)"""

# Convert the date strings into datetime objects
dataset['Date'] = pd.to_datetime(dataset['Date'])

"""Split data into X and y sets"""

# define X and y variables
X = dataset[[
    'Composite_HPI',
    'Single_Family_Benchmark',
    'One_Storey_Benchmark',
    'Two_Storey_Benchmark',
    'Townhouse_Benchmark',
    'Apartment_Benchmark'
    ]]
y = dataset[
    'Composite_Benchmark'
    ]

# varify the split data
print(f"X dataset example: {X}")
print(f"y dataset example: {y}")

"""Break data into Training and Test sets"""

# Split into 4 specific variables
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""Setup hyperparameters"""

# Define the parameter distribution
param_dist = {
    'n_estimators': [50, 100, 150, 200]
}

"""Instatiate the model"""

# plant the seeds to grow a forest
forest_model = RandomForestRegressor(random_state=0)

# Initiate the random search
random_search = RandomizedSearchCV(
    estimator = forest_model,  # use the model we created above
    param_distributions = param_dist,  # use the params we defined above
    n_iter = 15,  # Go over it 10 times
    cv = 5,  # Cross validation iterations
    scoring = 'neg_mean_squared_error',  # score output for performance
    random_state = 0
    )

"""Train the model"""

# Not tuned fit
forest_model.fit(X_train, y_train)

# call your model and pass in the training datasets
random_search.fit(X_train, y_train)  # Use the random_search now instead of forest object

"""Make the predictions you want it to output"""

# pass in X_test to predict a y value on forest model
y_predict = forest_model.predict(X_test)

print(f"Not Tuned: {y_predict}")

# Predict on the tuned model
tuned_pred = random_search.predict(X_test)

print(f"Tuned Predicition: {tuned_pred}")

"""Check the model"""

# pass in your y test data and check it against your y predicted data
mse = mean_squared_error(y_test, y_predict)
selected_params = random_search.best_params_

# share with the world!
print(f"Initial Mean Squared Error: {mse}")
print(f"Best Parameters to use: {selected_params}")

"""Re-Initialize Random Forest using the slected Params"""

# Instatiate another forest model with the selected parameters
final_forest = RandomForestRegressor(
    selected_params['n_estimators'],
    random_state=0
)

# Fit data to the new model
final_forest.fit(X_train, y_train)
final_pred = final_forest.predict(X_test)

final_mse = mean_squared_error(y_test, final_pred)

# Show hyper tuned MSE
print(f"Hyper Tuned Mean Squared Error: {final_mse}")
print(f"Final Predicted Data: {final_pred}")

"""Make a pretty graph!"""

# Fit a linear regression line to the data
# For the non-tuned actual vs predicted values
coefficients_non_tuned = np.polyfit(y_test, y_predict, 1)

# For the hyperparameter-tuned actual vs predicted values
coefficients_tuned = np.polyfit(y_test, final_pred, 1)

# Generate the regression lines
line_non_tuned = np.polyval(coefficients_non_tuned, y_test)
line_tuned = np.polyval(coefficients_tuned, y_test)

# Plot the non-tuned actual vs predicted values
plt.scatter(y_test, y_predict)
plt.plot(
    y_test,
    line_non_tuned,
    color='red',
    label='Regression Line'
    )
plt.xlabel('Actual Prices')
plt.ylabel('Predicted Prices')
plt.title('First Learning Graph')

# Adjust layout for better appearance
plt.tight_layout()

# Save the plot to a dynamic SVG file
plt.savefig('firstGraph.svg', format='svg', bbox_inches='tight')

plt.show()


# plot hyperparamer tuned actual vs predicted
plt.scatter(y_test, final_pred)
plt.plot(
    y_test,
    line_tuned,
    color='red',
    label='Regression Line'
    )
plt.xlabel('Actual Prices')
plt.ylabel('Predicted Prices')
plt.title('Hyper Parameter Tuned Graph')

# Adjust layout
plt.tight_layout()

# Save and show
plt.savefig('TunedGraph.svg', format='svg', bbox_inches='tight')

plt.show()

"""Try to predict next 10 years with new dataframe and trained/hyper tuned model"""

# Create a dataset for future dates
future_dates = pd.date_range(start='2024-01-01', periods=120, freq='M')
future_data = pd.DataFrame({'Date': future_dates})

# Add the old data to the new set
future_data['Composite_HPI'] = dataset['Composite_HPI']
future_data['Single_Family_Benchmark'] = dataset['Single_Family_Benchmark']
future_data['One_Storey_Benchmark'] = dataset['One_Storey_Benchmark']
future_data['Two_Storey_Benchmark'] = dataset['Two_Storey_Benchmark']
future_data['Townhouse_Benchmark'] = dataset['Townhouse_Benchmark']
future_data['Apartment_Benchmark'] = dataset['Apartment_Benchmark']

print(future_data)

# Grab the older data and apply it to the same dataframe
features_for_prediction = future_data[[
    'Composite_HPI',
    'Single_Family_Benchmark',
    'One_Storey_Benchmark',
    'Two_Storey_Benchmark',
    'Townhouse_Benchmark',
    'Apartment_Benchmark'
    ]]

# Use the model to predict future prices
future_predictions = final_forest.predict(
      features_for_prediction
    )

# Add the predicted prices to the future_data DataFrame
future_data['Composite_Benchmark_Predicted'] = future_predictions

"""Plot the Predicted actual prices"""

# Plot the predicted Composite Benchmark prices over time
plt.plot(future_data['Date'], future_data['Composite_Benchmark_Predicted'], label='Predicted Prices')

# Set up the axis
plt.xlabel('Year')
plt.ylabel('Composite Benchmark Prices')
plt.title('Next Ten Years Predicted Composite Benchmark Prices')

# Make the graph look nice
plt.tight_layout()
plt.legend()
plt.grid(True)

# Save the graph for a rainy day
plt.savefig('PredictionGraph.svg', format='svg', bbox_inches='tight')

# Display the graph to the end user
plt.show()