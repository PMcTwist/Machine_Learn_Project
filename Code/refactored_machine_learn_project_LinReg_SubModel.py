# -*- coding: utf-8 -*-
"""Refactored_Machine_Learn_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13hRsxDyWhORLZ0spbZAQGGjB51HP2Ciy

### Dependancy Imports
"""

# Basic imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime as dt

# Specific imports
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.impute import SimpleImputer
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import RandomizedSearchCV

"""### Import Data"""

# Assign data to variable
dataset = pd.read_csv('HousingData.csv')
dataset = dataset.head(229)

# Convert the date strings into datetime objects
dataset['Date'] = pd.to_datetime(dataset['Date'])

# Convert Date Features to a number format
dataset['Year'] = dataset['Date'].dt.year
dataset['Month'] = dataset['Date'].dt.month

# Take a small look at the dataframe produced
print(dataset.head())
print(dataset.shape)

"""### Split data in to features"""

# Split data into X and y sets
X = dataset[[
    'Year',
    'Month',
    'Composite_HPI',
    'Single_Family_Benchmark',
    'One_Storey_Benchmark',
    'Two_Storey_Benchmark',
    'Townhouse_Benchmark',
    'Apartment_Benchmark'
    ]]

y = dataset['Composite_Benchmark']

"""### Split the dataset"""

# Set up your sets into train and test variables
X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size = 0.2,
    random_state = 0
    )

# Show the user a sample of the dataset for reference
print(f"X-train sample: {X_train.head()}")
print(f"y-train sample: {y_train.head()}")

"""### Setup Basic Model"""

# Plant the seeds to grow a basic forest
forest_model = RandomForestRegressor(random_state = 0)

"""### Hyper Parameters"""

# Setup parameters
param_dist = {'n_estimators': [
    50,
    100,
    150,
    200,
    250,
    300,
    350,
    400,
    450,
    500,
    550,
    600,
    650,
    700,
    750
    ]}

# Initialize the random search
random_search = RandomizedSearchCV(
    estimator = forest_model,
    param_distributions = param_dist,
    n_iter = 15,
    cv = 5,
    scoring = 'neg_mean_squared_error',
    random_state = 0
)

# Fit the model
random_search.fit(X_train, y_train)

# Store the best selection for later
selected_params = random_search.best_params_

# Show the user the best parameter
print(f"Selected Param: {selected_params}")

"""### Final Model Set up"""

# Re-Initialize Random Forest using the selected Params
final_forest = RandomForestRegressor(
    n_estimators = selected_params['n_estimators'],
    random_state = 0
)

# Fit data to the new model
final_forest.fit(X_train, y_train)

# Make prediction to get a score to check
score_predict = final_forest.predict(X_test)

"""### Scoring"""

# Pass in your y test data and check it against your y predicted data
mse = mean_squared_error(y_test, score_predict)

# Share with the world!
print(f"Mean Squared Error: {mse}")

"""### Create Future Data"""

# Create a dataset for future dates
future_dates = pd.date_range(start='2024-01-01', periods=120, freq='M')
future_data = pd.DataFrame({'Date': future_dates})

# # Create future dataset with date features
future_data['Year'] = future_data['Date'].dt.year
future_data['Month'] = future_data['Date'].dt.month

both_sets = [dataset, future_data]

# Add the old data to the new set
new_data = pd.concat(both_sets)

"""### Linear Regression to backfill the Nulls"""

# Identify the missing data columns
missing_data_cols = [
    'Composite_HPI',
    'Single_Family_Benchmark',
    'One_Storey_Benchmark',
    'Two_Storey_Benchmark',
    'Townhouse_Benchmark',
    'Apartment_Benchmark'
]

# Iterate over the list of columns and predict the future for each
for col in missing_data_cols:
  print(col)

  missing_data = new_data[
      new_data[col].isnull()
      ]

  completed_data = new_data.dropna(subset = [col])

  # Break out the X and y sets for the backfill model
  # X_backfill = completed_data.select_dtypes(
  #     include = ['float64', 'int64']
  #     ).drop(
  #         columns = missing_data_cols
  #         )

  X_backfill = new_data[col].dropna()
  X_backfill = X_backfill.array.reshape(-1, 1)

  y_backfill = completed_data[col]

  # Instatiate a Linear Regression Model
  backfill_model = LinearRegression()

  # Fit the backfill model
  backfill_model.fit(X_backfill, y_backfill)

  # Predict what the missing values would be
  X_missing = missing_data[col].replace([np.nan], 0)
  X_missing = X_missing.array.reshape(-1, 1)

  imputer = SimpleImputer(
      strategy = 'mean',
      # missing_values=np.nan
      )

  X_missing_transformed = imputer.fit_transform(X_missing)

  predicted_future_data = backfill_model.predict(X_missing_transformed)

  print(predicted_future_data)

  # # Add the predicted data to the OG new_data object
  # new_data.iloc[
  #     missing_data.index,
  #     col
  #     ] = predicted_future_data

"""### Predict Outcome"""

# Grab features for prediction
features_for_prediction = new_data[[
    'Year',
    'Month',
    'Composite_HPI',
    'Single_Family_Benchmark',
    'One_Storey_Benchmark',
    'Two_Storey_Benchmark',
    'Townhouse_Benchmark',
    'Apartment_Benchmark'
    ]]

# Print a sample of the normalized future dataset
print(f"Normalized Future Data:\n {features_for_prediction}")

# Predict future prices
future_predictions = final_forest.predict(features_for_prediction)

print(future_predictions)

# Add predicted prices to future_data
future_data['Composite_Benchmark_Predicted'] = future_predictions

"""### Graphs"""

# Plot the predicted Composite Benchmark prices over time
plt.plot(
    future_data['Date'],
    future_data['Composite_Benchmark_Predicted'],
    label='Predicted Prices'
    )

# Set up the axis
plt.xlabel('Year')
plt.ylabel('Predicted Prices')
plt.title('Next Ten Years Predicted Composite Benchmark Prices')

# Make the graph look nice
plt.tight_layout()
plt.legend()
plt.grid(True)

# Save the graph for a rainy day
plt.savefig('PredictionGraph.svg', format='svg', bbox_inches='tight')

# Display the graph to the end user
plt.show()