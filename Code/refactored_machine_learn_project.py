# -*- coding: utf-8 -*-
"""Refactored_Machine_Learn_Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iOmClaDoJuRqTFxs6AUCM3qMeSYDMPHi

### Dependancy Imports
"""

# Basic imports
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from datetime import datetime as dt

# Specific imports
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import RandomizedSearchCV

"""### Import Data"""

# Assign data to variable
dataset = pd.read_csv('HousingData.csv')
dataset = dataset.head(229)

# Convert the date strings into datetime objects
dataset['Date'] = pd.to_datetime(dataset['Date'])

# Convert Date Features to a number format
dataset['Year'] = dataset['Date'].dt.year
dataset['Month'] = dataset['Date'].dt.month

# Take a small look at the dataframe produced
print(dataset.head())
print(dataset.shape)

"""### Split data in to features"""

# Split data into X and y sets
X = dataset[[
    'Year',
    'Month',
    'Composite_HPI',
    'Single_Family_Benchmark',
    'One_Storey_Benchmark',
    'Two_Storey_Benchmark',
    'Townhouse_Benchmark',
    'Apartment_Benchmark'
    ]]

y = dataset['Composite_Benchmark']

"""### Split the dataset"""

# Set up your sets into train and test variables
X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size = 0.2,
    random_state = 0
    )

# Show the user a sample of the dataset for reference
print(f"X-train sample: {X_train.head()}")
print(f"y-train sample: {y_train.head()}")

"""### Setup Basic Model"""

# Plant the seeds to grow a basic forest
forest_model = RandomForestRegressor(random_state = 0)

"""### Hyper Parameters"""

# Setup parameters
param_dist = {'n_estimators': [
    50,
    100,
    150,
    200,
    250,
    300,
    350,
    400,
    450,
    500,
    550,
    600,
    650,
    700,
    750
    ]}

# Initialize the random search
random_search = RandomizedSearchCV(
    estimator = forest_model,
    param_distributions = param_dist,
    n_iter = 15,
    cv = 5,
    scoring = 'neg_mean_squared_error',
    random_state = 0
)

# Fit the model
random_search.fit(X_train, y_train)

# Store the best selection for later
selected_params = random_search.best_params_

# Show the user the best parameter
print(f"Selected Param: {selected_params}")

"""### Final Model Set up"""

# Re-Initialize Random Forest using the selected Params
final_forest = RandomForestRegressor(
    n_estimators = selected_params['n_estimators'],
    random_state = 0
)

# Fit data to the new model
final_forest.fit(X_train, y_train)

# Make prediction to get a score to check
score_predict = final_forest.predict(X_test)

"""### Scoring"""

# Pass in your y test data and check it against your y predicted data
mse = mean_squared_error(y_test, score_predict)

# Share with the world!
print(f"Mean Squared Error: {mse}")

"""### Create Future Data"""

# Create a dataset for future dates
future_dates = pd.date_range(start='2024-01-01', periods=120, freq='M')
future_data = pd.DataFrame({'Date': future_dates})

# Add the old data to the new set
future_data['Composite_HPI'] = dataset['Composite_HPI']
future_data['Single_Family_Benchmark'] = dataset['Single_Family_Benchmark']
future_data['One_Storey_Benchmark'] = dataset['One_Storey_Benchmark']
future_data['Two_Storey_Benchmark'] = dataset['Two_Storey_Benchmark']
future_data['Townhouse_Benchmark'] = dataset['Townhouse_Benchmark']
future_data['Apartment_Benchmark'] = dataset['Apartment_Benchmark']

# Create future dataset with date features
future_data['Year'] = future_data['Date'].dt.year
future_data['Month'] = future_data['Date'].dt.month

# Grab features for prediction
features_for_prediction = future_data[[
    'Year',
    'Month',
    'Composite_HPI',
    'Single_Family_Benchmark',
    'One_Storey_Benchmark',
    'Two_Storey_Benchmark',
    'Townhouse_Benchmark',
    'Apartment_Benchmark'
    ]]

# Print a sample of the normalized future dataset
print(f"Normalized Future Data:\n {features_for_prediction.head()}")

"""### Predict Outcome"""

# Predict future prices
future_predictions = final_forest.predict(features_for_prediction)

print(future_predictions)

# Add predicted prices to future_data
future_data['Composite_Benchmark_Predicted'] = future_predictions

"""### Graphs"""

# Plot the predicted Composite Benchmark prices over time
plt.plot(
    future_data['Date'],
    future_data['Composite_Benchmark_Predicted'],
    label='Predicted Prices'
    )

# Set up the axis
plt.xlabel('Year')
plt.ylabel('Predicted Prices')
plt.title('Next Ten Years Predicted Composite Benchmark Prices')

# Make the graph look nice
plt.tight_layout()
plt.legend()
plt.grid(True)

# Save the graph for a rainy day
plt.savefig('PredictionGraph.svg', format='svg', bbox_inches='tight')

# Display the graph to the end user
plt.show()